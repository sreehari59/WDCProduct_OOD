{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb69321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "from pdb import set_trace\n",
    "\n",
    "from statistics import median, mean\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.parsing.preprocessing import lower_to_unicode, preprocess_string, strip_tags, strip_punctuation, strip_multiple_whitespaces, strip_numeric\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee859b70",
   "metadata": {},
   "source": [
    "# Load cleansed PDC2020 corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5a8556",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.read_pickle('../../../data/interim/wdc-lspc/corpus/dedup_preprocessed_lspcV2020_only_en_strict_only_long_title_only_mainentity.pkl.gz')\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4418772",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = corpus['cluster_id'].value_counts()\n",
    "counts = counts[counts > 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a056a8",
   "metadata": {},
   "source": [
    "# Apply DBSCAN clustering and save it for manual labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81d24e8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "eps_list = [0.35]\n",
    "min_samples_list = [1]\n",
    "\n",
    "for eps in eps_list:\n",
    "    for min_sample in min_samples_list:\n",
    "        print(f'eps: {eps}, min_samples: {min_sample}')\n",
    "        \n",
    "        corpus_selection = corpus[corpus['cluster_id'].isin(counts.index)].copy()\n",
    "        corpus_selection = corpus_selection.drop_duplicates('cluster_id')\n",
    "        CUSTOM_FILTERS = [lambda x: x.lower(), strip_tags, strip_punctuation, strip_multiple_whitespaces]\n",
    "\n",
    "        corpus_selection['title_processed'] = corpus_selection['title'].apply(lower_to_unicode)\n",
    "        corpus_selection['title_processed'] = corpus_selection['title_processed'].apply(preprocess_string, args=(CUSTOM_FILTERS,))\n",
    "        corpus_selection['title_processed'] = corpus_selection['title_processed'].apply(lambda x: ' '.join(x))\n",
    "        \n",
    "        vectorizer = CountVectorizer(strip_accents='unicode', binary=True, min_df=4)\n",
    "        #vectorizer = TfidfVectorizer(strip_accents='unicode', use_idf=False)\n",
    "        matrix = vectorizer.fit_transform(corpus_selection['title_processed'])\n",
    "\n",
    "        dbscan = DBSCAN(metric='cosine', eps=eps, min_samples=min_sample)\n",
    "        #dbscan = OPTICS(metric='cosine', max_eps=eps, eps=eps, min_samples=min_sample, cluster_method='dbscan')\n",
    "        clustering = dbscan.fit(matrix)\n",
    "        corpus_selection['dbscan_cluster'] = clustering.labels_\n",
    "        \n",
    "        counts_relevant = corpus['cluster_id'].value_counts()\n",
    "\n",
    "        counts_relevant_unseen = counts_relevant[counts_relevant > 3]\n",
    "        counts_relevant_unseen = counts_relevant_unseen[counts_relevant_unseen < 7]\n",
    "        \n",
    "        counts_relevant_seen = counts_relevant[counts_relevant > 6]\n",
    "        counts_relevant_seen = counts_relevant_seen[counts_relevant_seen < 81]\n",
    "        \n",
    "        print(f'Seen data:')\n",
    "        corpus_selection_seen = corpus_selection[corpus_selection['cluster_id'].isin(counts_relevant_seen.index)].copy()\n",
    "        corpus_selection_seen = corpus_selection_seen[corpus_selection_seen['dbscan_cluster'] != -1]\n",
    "        \n",
    "        print(f'Clusters found: {len(corpus_selection_seen[\"dbscan_cluster\"].unique())}')\n",
    "        print(f'Mean cluster size: {mean(corpus_selection_seen[\"dbscan_cluster\"].value_counts())}, Median cluster_size: {median(corpus_selection_seen[\"dbscan_cluster\"].value_counts())}')\n",
    "        \n",
    "        counts_clustering = corpus_selection_seen['dbscan_cluster'].value_counts()\n",
    "        counts_clustering = counts_clustering[counts_clustering > 2]\n",
    "        corpus_selection_seen = corpus_selection_seen[corpus_selection_seen['dbscan_cluster'].isin(counts_clustering.index)]\n",
    "        corpus_selection_seen = corpus_selection_seen.sort_values('dbscan_cluster')\n",
    "        \n",
    "        print(f'Clusters >2 found: {len(corpus_selection_seen[\"dbscan_cluster\"].unique())}')\n",
    "        print(f'Mean cluster size: {mean(corpus_selection_seen[\"dbscan_cluster\"].value_counts())}, Median cluster_size: {median(corpus_selection_seen[\"dbscan_cluster\"].value_counts())}\\n')\n",
    "        corpus_selection_seen = corpus_selection_seen[['dbscan_cluster', 'brand', 'title', 'description', 'price', 'priceCurrency',\n",
    "       'specTableContent', 'id', 'cluster_id', 'sku', 'mpn', 'gtin', 'gtin8',\n",
    "       'gtin12', 'gtin13', 'gtin14', 'productID', 'identifier']]\n",
    "        \n",
    "        corpus_selection_seen.to_excel(f'../../../data/interim/wdc-lspc/corpus/seen_dbscan_eps{eps}_minsamples{min_sample}_dedup_preprocessed_lspcV2020_only_en_strict_only_long_title_only_mainentity.xlsx', header=True, index=False)\n",
    "        \n",
    "        db_clu = corpus_selection_seen[['cluster_id', 'dbscan_cluster']].copy()\n",
    "        db_clu = db_clu.drop_duplicates('cluster_id')\n",
    "        db_clu.to_csv(f'../../../data/interim/wdc-lspc/corpus/seen_dbscan_mapping.csv', header=True, index=False)\n",
    "        db_clu = corpus_selection_seen['dbscan_cluster'].copy()\n",
    "        db_clu = db_clu.drop_duplicates()\n",
    "        db_clu = db_clu.sort_values()\n",
    "        db_clu.to_csv(f'../../../data/interim/wdc-lspc/corpus/seen_dbscan_clusters.csv', header=True, index=False)\n",
    "        \n",
    "        print(f'Unseen data:')\n",
    "        corpus_selection_unseen = corpus_selection[corpus_selection['cluster_id'].isin(counts_relevant_unseen.index)].copy()\n",
    "        corpus_selection_unseen = corpus_selection_unseen[corpus_selection_unseen['dbscan_cluster'] != -1]\n",
    "        \n",
    "        print(f'Clusters found: {len(corpus_selection_unseen[\"dbscan_cluster\"].unique())}')\n",
    "        print(f'Mean cluster size: {mean(corpus_selection_unseen[\"dbscan_cluster\"].value_counts())}, Median cluster_size: {median(corpus_selection_unseen[\"dbscan_cluster\"].value_counts())}')\n",
    "        \n",
    "        counts_clustering = corpus_selection_unseen['dbscan_cluster'].value_counts()\n",
    "        counts_clustering = counts_clustering[counts_clustering > 2]\n",
    "        corpus_selection_unseen = corpus_selection_unseen[corpus_selection_unseen['dbscan_cluster'].isin(counts_clustering.index)]\n",
    "        corpus_selection_unseen = corpus_selection_unseen.sort_values('dbscan_cluster')\n",
    "        \n",
    "        print(f'Clusters >2 found: {len(corpus_selection_unseen[\"dbscan_cluster\"].unique())}')\n",
    "        print(f'Mean cluster size: {mean(corpus_selection_unseen[\"dbscan_cluster\"].value_counts())}, Median cluster_size: {median(corpus_selection_unseen[\"dbscan_cluster\"].value_counts())}\\n')\n",
    "        corpus_selection_unseen = corpus_selection_unseen[['dbscan_cluster', 'brand', 'title', 'description', 'price', 'priceCurrency',\n",
    "       'specTableContent', 'id', 'cluster_id', 'sku', 'mpn', 'gtin', 'gtin8',\n",
    "       'gtin12', 'gtin13', 'gtin14', 'productID', 'identifier']]\n",
    "        \n",
    "        corpus_selection_unseen.to_excel(f'../../../data/interim/wdc-lspc/corpus/unseen_dbscan_eps{eps}_minsamples{min_sample}_dedup_preprocessed_lspcV2020_only_en_strict_only_long_title_only_mainentity.xlsx', header=True, index=False)\n",
    "        \n",
    "        db_clu = corpus_selection_unseen[['cluster_id', 'dbscan_cluster']].copy()\n",
    "        db_clu = db_clu.drop_duplicates('cluster_id')\n",
    "        db_clu.to_csv(f'../../../data/interim/wdc-lspc/corpus/unseen_dbscan_mapping.csv', header=True, index=False)\n",
    "        db_clu = corpus_selection_unseen['dbscan_cluster'].copy()\n",
    "        db_clu = db_clu.drop_duplicates()\n",
    "        db_clu = db_clu.sort_values()\n",
    "        db_clu.to_csv(f'../../../data/interim/wdc-lspc/corpus/unseen_dbscan_clusters.csv', header=True, index=False)\n",
    "\n",
    "        print(f'-------------------------------------------------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
